{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Classification\n",
    "\n",
    "## Background\n",
    "\n",
    "In a scenario where an algorithm classifies sectors for different texts, it is important to measure its classification. This makes it possible to understand the worst assertiveness rate and propose solutions for improvement.\n",
    "This project aims to develop a model that classifies different subjects for sentences and evaluates their quality.\n",
    "\n",
    "The project was made possible according to the [proposed planning](../docs/planning.md)\n",
    "\n",
    "## Measure of Success\n",
    "\n",
    "As we want to understand which are the worst classifications, metrics such as Recall and Precision are able to correctly measure the correct classifications, in this case we will use F1-Score which harmonizes the metrics. In addition, we will analyze the confusion matrix and AUC Curve to identify the classifications for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas                            as pd\n",
    "import string\n",
    "import re\n",
    "import numpy                             as np\n",
    "\n",
    "from collections import Counter\n",
    "import seaborn                           as sns\n",
    "import matplotlib.pyplot                 as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem                          import WordNetLemmatizer\n",
    "from nltk.corpus                        import stopwords, wordnet\n",
    "\n",
    "from sklearn.preprocessing              import MultiLabelBinarizer\n",
    "from sklearn.model_selection            import train_test_split\n",
    "from sklearn.metrics                    import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from wordcloud                          import WordCloud\n",
    "\n",
    "from keras.preprocessing.text           import Tokenizer\n",
    "from keras.preprocessing.sequence       import pad_sequences\n",
    "import tensorflow                       as tf\n",
    "from tensorflow.keras                   import backend as K\n",
    "from keras                              import saving\n",
    "from tensorflow.keras.layers            import Input, SpatialDropout1D, Conv1D, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models            import Model\n",
    "from tensorflow.keras.regularizers      import l1_l2\n",
    "from keras.callbacks                    import EarlyStopping\n",
    "from keras.models                       import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/01_raw/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Helper Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notebook_settings():\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', 60)\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "    plt.style.use('bmh')\n",
    "    plt.rcParams['figure.figsize'] = [20, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    sns.set()\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    return None\n",
    "\n",
    "\n",
    "def lemmatize_word(word, lemmatizer):\n",
    "    lemma = lemmatizer.lemmatize(word, pos=wordnet.VERB)\n",
    "    return lemmatizer.lemmatize(lemma, pos=wordnet.NOUN)\n",
    "\n",
    "\n",
    "def process_text(text, lemmatizer, portuguese_stopword):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered_and_lemmatized_words = [lemmatize_word(word, lemmatizer) for word in words if word.lower() not in portuguese_stopword]\n",
    "    text = ' '.join(filtered_and_lemmatized_words)\n",
    "    \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def f2_score(y_true, y_pred):\n",
    "    beta_squared = 4\n",
    "\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    fbeta_score = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "    return K.mean(fbeta_score)\n",
    "\n",
    "\n",
    "def sample_prediction_multilabel(model, tokenizer, validation_data, original_data, mlb, MAX_SEQUENCE_LENGTH, num_samples=5, threshold=0.5):\n",
    "    sample_indices = np.random.choice(validation_data.index, size=num_samples, replace=False)\n",
    "\n",
    "    sample_texts_processed = validation_data.loc[sample_indices, 'sentence'].tolist()\n",
    "    sample_texts_original = original_data.loc[sample_indices, 'sentence'].tolist()\n",
    "\n",
    "    sample_true_categories = validation_data.loc[sample_indices, mlb.classes_].values\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(sample_texts_processed)\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    predicted_categories = (predictions > threshold).astype(int)\n",
    "    \n",
    "    for i, (text, true_cats, pred_cats) in enumerate(zip(sample_texts_original, sample_true_categories, predicted_categories)):\n",
    "        print('-' * 100)\n",
    "        print(f\"Sample {i+1}\")\n",
    "        print(f\"Original Text: {text}\")\n",
    "        print(f\"True Categories: {[mlb.classes_[i] for i, val in enumerate(true_cats) if val == 1]}\")\n",
    "        print(f\"Predicted Categories: {[mlb.classes_[i] for i, val in enumerate(pred_cats) if val == 1]}\")\n",
    "    print('-' * 100)\n",
    "    return None\n",
    "\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def plot_multilabel_confusion_matrix(y_true, y_pred, labels, figsize=(15, 10)):\n",
    "    n_labels = y_true.shape[1]\n",
    "    \n",
    "    fig, axs = plt.subplots(int(np.ceil(n_labels / 3)), 3, figsize=figsize)\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i in range(n_labels):\n",
    "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axs[i])\n",
    "        axs[i].set_title(labels[i])\n",
    "        axs[i].set_xlabel('Predicted Label')\n",
    "        axs[i].set_ylabel('True Label')\n",
    "\n",
    "    for i in range(n_labels, len(axs)):\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "notebook_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Data Descrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description = df_raw.copy()\n",
    "\n",
    "data_description.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Check NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    object\n",
       "category    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We don't have any visible problems with the data, so let's do some more in-depth analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis = data_description.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "orgão público              0.269\n",
       "educação                   0.205\n",
       "indústrias                 0.171\n",
       "varejo                     0.163\n",
       "finanças                   0.104\n",
       "finanças,varejo            0.025\n",
       "educação,orgão público     0.017\n",
       "indústrias,varejo          0.013\n",
       "educação,indústrias        0.010\n",
       "finanças,orgão público     0.008\n",
       "finanças,indústrias        0.006\n",
       "indústrias,orgão público   0.004\n",
       "educação,finanças          0.004\n",
       "varejo,indústrias          0.002\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analysis['category'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "orgão público               140\n",
       "educação                    107\n",
       "indústrias                   89\n",
       "varejo                       85\n",
       "finanças                     54\n",
       "finanças,varejo              13\n",
       "educação,orgão público        9\n",
       "indústrias,varejo             7\n",
       "educação,indústrias           5\n",
       "finanças,orgão público        4\n",
       "finanças,indústrias           3\n",
       "indústrias,orgão público      2\n",
       "educação,finanças             2\n",
       "varejo,indústrias             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analysis['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have unbalanced data, which is to be expected, but we also have some classes such as 1 occurrence, which can get in the way of dividing up the data; if we need to improve the model, we can apply class balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210    21\n",
       "193    20\n",
       "303    20\n",
       "507    20\n",
       "362    20\n",
       "       ..\n",
       "64      3\n",
       "386     3\n",
       "491     3\n",
       "244     3\n",
       "212     3\n",
       "Name: sentence_lenght, Length: 521, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analysis['sentence_lenght'] = data_analysis['sentence'].apply(lambda x: len(str(x).split()))\n",
    "data_analysis['sentence_lenght'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Para se enquadrar nesta categoria é necessário apresentar o comprovante de produtor rural, o ITR – Imposto sobre propriedade Territorial Rural.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_analysis.iloc[210, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We don't have long sentences, which makes it easier for models not to have to maintain a long context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Most Used Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>de</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>do</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>o</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>a</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>para</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>em</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>da</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>com</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>no</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>na</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>seu</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>é</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>DE</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>que</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>R$</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>os</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>por</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>mais</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  count\n",
       "22     de    351\n",
       "5       e    145\n",
       "24     do    106\n",
       "110     o     99\n",
       "30      a     93\n",
       "42   para     89\n",
       "3      em     72\n",
       "20     da     65\n",
       "120   com     54\n",
       "216    no     40\n",
       "15     na     38\n",
       "191     -     35\n",
       "126   seu     34\n",
       "32      é     30\n",
       "330    DE     28\n",
       "302   que     27\n",
       "164    R$     26\n",
       "18     os     26\n",
       "49    por     25\n",
       "78   mais     24"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts = ''.join(data_analysis['sentence'])\n",
    "\n",
    "words = all_texts.split()\n",
    "\n",
    "word_counts = Counter(words)\n",
    "df_words = pd.DataFrame(word_counts.items(), columns=['word','count'])\n",
    "\n",
    "\n",
    "df_words.sort_values(by='count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have a lot of `stopwords`, which is to be expected, so we'll deal with those cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
